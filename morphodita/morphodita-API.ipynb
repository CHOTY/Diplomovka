{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'ufal.morphodita.Tagger' object has no attribute 'setLemmaAlphabet'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 11\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTagger sa nepodarilo načítať. Skontrolujte cestu k modelu.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Nastavenie lemmatizácie\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m \u001b[43mtagger\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msetLemmaAlphabet\u001b[49m(ufal\u001b[38;5;241m.\u001b[39mmorphodita\u001b[38;5;241m.\u001b[39mAlphabet())\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Tokenizácia\u001b[39;00m\n\u001b[0;32m     14\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m ufal\u001b[38;5;241m.\u001b[39mmorphodita\u001b[38;5;241m.\u001b[39mTokenizer\u001b[38;5;241m.\u001b[39mnewGenericTokenizer()\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'ufal.morphodita.Tagger' object has no attribute 'setLemmaAlphabet'"
     ]
    }
   ],
   "source": [
    "import stanza\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "# Načítanie textového súboru\n",
    "def read_text_file(filepath):\n",
    "    with open(filepath, \"r\", encoding=\"utf-8\") as file:\n",
    "        return file.read()\n",
    "\n",
    "# Funkcia na posielanie požiadavky na MorphoDiTa API\n",
    "def tag_with_morphodita(sentence):\n",
    "    api_url = \"https://lindat.mff.cuni.cz/services/morphodita/api/tag?\"\n",
    "    params = {\n",
    "        \"data\": sentence,\n",
    "        \"model\": \"slovak-morfflex-pdt-170914-no_dia\",  # Definovanie modelu priamo tu\n",
    "        \"guesser\": \"yes\",  # Použiť morfologický hádač\n",
    "        \"input\": \"untokenized\",  # Vstup ako obyčajný text\n",
    "        \"convert_tagset\": \"strip_lemma_id\",  # Upraviť tag set\n",
    "        \"output\": \"json\"  # JSON formát výstupu\n",
    "    }\n",
    "    response = requests.get        (api_url, params=params)\n",
    "    print(response)\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        raise Exception(f\"Chyba API: {response.status_code} - {response.text}\")\n",
    "\n",
    "# Cesta k textovému súboru\n",
    "filepath = r\"C:\\Users\\marti\\Downloads\\DiploDiktaty.txt\"\n",
    "text = read_text_file(filepath)\n",
    "\n",
    "# Inicializácia Stanza pre tokenizáciu\n",
    "stanza.download('sk')\n",
    "nlp = stanza.Pipeline(lang='sk', processors='tokenize')\n",
    "\n",
    "# Tokenizácia textu na vety\n",
    "document = nlp(text)\n",
    "\n",
    "# Príprava dát na uloženie\n",
    "sentences_data = []  # Pre CSV s vetami\n",
    "words_data = []      # Pre CSV so slovami\n",
    "\n",
    "# Prechádzanie cez tokenizované vety\n",
    "for sentence_id, sentence in enumerate(document.sentences, start=1):\n",
    "    sentences_data.append([sentence_id, sentence.text])  # Uloženie vety s ID\n",
    "    try:\n",
    "        # Tagovanie cez MorphoDiTa API\n",
    "        morphodita_result = tag_with_morphodita(sentence.text)\n",
    "\n",
    "        # Spracovanie výsledkov API\n",
    "        if \"result\" in morphodita_result and isinstance(morphodita_result[\"result\"], list):\n",
    "            for token in morphodita_result[\"result\"]:\n",
    "                words_data.append([\n",
    "                    sentence_id,             # ID vety\n",
    "                    token.get(\"token\", \"\"),  # Token (slovo)\n",
    "                    token.get(\"lemma\", \"\"),  # Lemma\n",
    "                    token.get(\"tag\", \"\")     # Morfologický tag\n",
    "                ])\n",
    "        else:\n",
    "            print(f\"Odpoveď API nemá správny formát pre vetu: {sentence.text}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Chyba pri spracovaní vety '{sentence.text}': {e}\")\n",
    "\n",
    "# Uloženie výsledkov do CSV\n",
    "sentences_df = pd.DataFrame(sentences_data, columns=[\"Sentence_ID\", \"Text\"])\n",
    "words_df = pd.DataFrame(words_data, columns=[\"Sentence_ID\", \"Token\", \"Lemma\", \"Tag\"])\n",
    "\n",
    "sentences_df.to_csv(\"sentences.csv\", index=False, encoding=\"utf-8\")\n",
    "words_df.to_csv(\"words.csv\", index=False, encoding=\"utf-8\")\n",
    "\n",
    "print(\"Výstup uložený do 'sentences.csv' a 'words.csv'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = r\"C:\\Users\\marti\\Downloads\\DiploDiktaty.txt\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
