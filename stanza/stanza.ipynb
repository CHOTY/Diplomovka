{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import stanza\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Načítanie textového súboru\n",
    "def read_text_file(filepath):\n",
    "    with open(filepath, \"r\", encoding=\"utf-8\") as file:\n",
    "        text = file.read()\n",
    "    return text\n",
    "\n",
    "filepath = r\"C:\\Users\\marti\\Downloads\\DiploDiktaty.txt\"\n",
    "text = read_text_file(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48572bd2e0e9410b8bd453ceb8306a62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.10.0.json:   0%|  …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-12 14:13:05 INFO: Downloaded file to C:\\Users\\marti\\stanza_resources\\resources.json\n",
      "2025-01-12 14:13:05 INFO: Downloading default packages for language: sk (Slovak) ...\n",
      "2025-01-12 14:13:05 INFO: File exists: C:\\Users\\marti\\stanza_resources\\sk\\default.zip\n",
      "2025-01-12 14:13:06 INFO: Finished downloading models and saved to C:\\Users\\marti\\stanza_resources\n",
      "2025-01-12 14:13:06 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ec3d204394c4aa585bf60707fc71d04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.10.0.json:   0%|  …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-12 14:13:07 INFO: Downloaded file to C:\\Users\\marti\\stanza_resources\\resources.json\n",
      "2025-01-12 14:13:07 INFO: Loading these models for language: sk (Slovak):\n",
      "============================\n",
      "| Processor | Package      |\n",
      "----------------------------\n",
      "| tokenize  | snk          |\n",
      "| mwt       | snk          |\n",
      "| pos       | snk_nocharlm |\n",
      "| lemma     | snk_nocharlm |\n",
      "| depparse  | snk_nocharlm |\n",
      "============================\n",
      "\n",
      "2025-01-12 14:13:07 INFO: Using device: cpu\n",
      "2025-01-12 14:13:07 INFO: Loading: tokenize\n",
      "2025-01-12 14:13:08 INFO: Loading: mwt\n",
      "2025-01-12 14:13:08 INFO: Loading: pos\n",
      "2025-01-12 14:13:09 INFO: Loading: lemma\n",
      "2025-01-12 14:13:09 INFO: Loading: depparse\n",
      "2025-01-12 14:13:09 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "stanza.download('sk')\n",
    "nlp = stanza.Pipeline(lang='sk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dokument = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = []\n",
    "words = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['už', 'už', 'T', '-', '-', '-', '-', '-', '-', 2]\n"
     ]
    }
   ],
   "source": [
    "# Príprava dát na ukladanie\n",
    "sentences_data = []  # Zoznam pre vety (s ID a textom)\n",
    "words_data = []      # Zoznam pre slová\n",
    "\n",
    "# Prechádzanie cez vety a slová\n",
    "for sentence_id, veta in enumerate(dokument.sentences, start=1):\n",
    "    # Pridanie ID vety a jej textu do zoznamu viet\n",
    "    sentences_data.append([sentence_id, veta.text])\n",
    "    for slovo in veta.words:\n",
    "        # Rozdelenie XPOS na jednotlivé časti\n",
    "        xpos = slovo.xpos or '-'\n",
    "        xpos_parts = [xpos[i] if i < len(xpos) else '-' for i in range(7)]\n",
    "   \n",
    "\n",
    "        # Pridanie dát o slovách do zoznamu\n",
    "        words.append([\n",
    "            slovo.text,   # Token (slovo)\n",
    "            slovo.lemma,  # Lemma\n",
    "            xpos_parts[0], xpos_parts[1], xpos_parts[2], xpos_parts[3], xpos_parts[4], xpos_parts[5], xpos_parts[6], # XPOS rozdelené na jednotlivé časti\n",
    "            slovo.id,     # ID slova vo vete  \n",
    "        ])\n",
    "print(words[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vety uložené do 'sentences.csv'.\n",
      "Slová uložené do 'words.csv'.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Vytvorenie DataFrame pre vety\n",
    "sentences_df = pd.DataFrame(sentences_data, columns=['Sentence_ID', 'Text'])\n",
    "\n",
    "# Vytvorenie DataFrame pre slová\n",
    "words_df = pd.DataFrame(words, columns=[\n",
    "    'Token', 'Lemma','Xpos1', 'Xpos2', 'Xpos3', 'Xpos4', 'Xpos5', 'Xpos6', 'Xpos7','ID'\n",
    "])\n",
    "\n",
    "# Uloženie do CSV súborov\n",
    "sentences_df.to_excel(\"sentences.xlsx\", index=False, engine=\"openpyxl\")\n",
    "words_df.to_excel(\"output.xlsx\", index=False, engine=\"openpyxl\")\n",
    "\n",
    "print(\"Vety uložené do 'sentences.csv'.\")\n",
    "print(\"Slová uložené do 'words.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
